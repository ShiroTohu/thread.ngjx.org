import { cn } from '@utils'
import { Callout, Steps } from 'nextra/components'
import { Statuses, ThreadStatuses, ThreadExceptions } from '@components/typedata'


export function ArgumentWrapper({ children, className, ...props }) {return (
  <details {...props} className={cn('last-of-type:mb-0 rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2 mt-4', className)}>
    {children}
  </details>
)}

export function ArgumentBody({ children, className, ...props }) {return (
  <div {...props} className={cn('nx-p-2', className)}>
    {children}
  </div>
)}

export function ArgumentExtra({ children, className, ...props }) {return (
  <span {...props} className={cn('ml-4 text-neutral-500', className)}>
    {children}
  </span>
)}

export function TabbedData({ type, keys = [] }) {return (
  <Tabs items={keys}>
    {keys.map(key => (
      <Tabs.Tab>{type === 'status' ? ThreadStatuses[key] : ThreadExceptions[key]}</Tabs.Tab>
    ))}
  </Tabs>
)}



# Parallel Processing Documentation

Documentation for `thread.ParallelProcessing`.



## Why Parallel Processing?

Parallel Processing is used to speed up the data processing of large datasets by splitting workflow into multiple threads.

Traditionally, this is achieved with a for loop.
```py
my_dataset = [] # Large dataset
def my_data_processor(Data_In) -> Data_Out:
  ...

processed_data = []
for data in my_dataset:
  processed_data = my_data_processor(data)

print(processed_data) # Processed data
```

While this is simple and decent enough for a small dataset, this is not ideal for large datasets, especially when runtime matters.
By using `thread.ParallelProcessing` we can split the large dataset into multiple chunks and process each chunk simultaneously.

<Callout>
  Parallel Processing is not True Parallel.
  Learn more [here](/learn/cautions/parallelism).
</Callout>



## How It Works

<Steps>

  ### Determine Thread Count

  The number of threads used is determined by the following formula:
  ```py
  thread_count = min(max_threads, len(dataset))
  ```

  This ensures that the number of threads used will always be less than or equal to the length of the dataset,
  which prevents redundant threads to be initialized for small datasets.

  ### Chunking

  The dataset is split as evenly as possible into chunks, preserving the order of data.
  Chunks follow the structure:
  ```py
  chunks = [[1, 2, 3, ...], [50, 51, 52, ...], ...]
  ```

  Let $N$ be the length of the dataset
  and let $M$ be the number of threads.

  The individual chunk lengths decrease down the chunk list.
  The length of each chunk will can be either $\lfloor{N/M + 0.5}\rfloor + 1$ or $N/M$.

  <Callout type='warning'>
    The chunks generated are not generators, meaning they will exist alongside `dataset` and take up memory.
    This will change to more memory-efficient generators in `v1.0.1`.
  </Callout>

</Steps>



## Importing the class

```py
import thread
thread.ParallelProcessing

from thread import ParallelProcessing
```



## Quick Start

There are main 2 ways of initializing a parallel processing object.

### On-Demand
You can create a simple process by initializing `thread.ParallelProcessing` and parsing the `function` and `dataset`.
```py
def my_data_processor(Data_In) -> Data_Out: ...

# Recommended way
my_processor = ParallelProcessing(
  function = my_data_processor,
  dataset = [i in range(0, n)]
)

# OR
# Not the recommended way
my_processor = ParallelProcessing(my_data_processor, [i in range(0, n)])
```

It can be ran by invoking the `start()` method
```py
my_processor.start()
```

### Decorated Function
You can decorate a function with `thread.processor` which uses `thread.ParallelProcessing`.
When the decorated function is invoked, it will automatically be ran in a new thread each time and return a `thread.ParallelProcessing` object.

A decorated function's signature is overwritten, replacing the first argument to require a sequence of the `Data_In` type.

```python
import thread

@thread.processor
def my_target(Data_In, arg1, arg2, *, arg3: bool = False) -> Data_Out: ...

dataset: Sequence[type[Data_In]]
worker = my_target(dataset, arg1, arg2, arg3 = True) # thread.ParallelProcessing()
```

<Callout type='info'>
  Did you know?

  Decorators can take in keyword arguments that change the behavior of the thread.
  ```py
  import thread

  @thread.processor(name = 'my_thread', suppress_errors = True)
  def my_target(): ...
  ```

  See the full list of arguments [here](#initialization)

</Callout>



## Initialization

This will cover the required and optional arguments initializing a parallel process.

### Required

<ArgumentWrapper>
  <summary>
    <strong className='text-lg'>
      function
      <ArgumentExtra>(Data_In, *args, **kwargs) -> Data_Out</ArgumentExtra>
    </strong>
  </summary>
  <ArgumentBody>
    This should be a function that takes in a data from the `dataset` with/without overloads and returns Data_Out.

    Arguments and keyword arguments excluding the first argument parsed to the `function` can be parsed through `args` and `kwargs`.
    `Data_Out` will be written to the generated thread's `Thread._returned_value` and can be accessed via `ParallelProcessing.results` or `ParallelProcessing.get_return_values()`.

    `function` can be parsed as the first argument to `ParallelProcessing.__init__()`, although it is recommended to use only keyword arguments.
    ```py
    import thread

    thread.ParallelProcessing(lambda x: x + 1, [])
    thread.ParallelProcessing(function = lambda x: x + 1, dataset = [])
    ```

    <Callout type='info'>
      Best Practices

      While you can use a lambda function, it is best to use a normal function for your LSP/Linter to infer types.
      ```py
      from thread import ParallelProcessing

      worker = ParallelProcessing(function = lambda x: x + 1, dataset = [1, 2, 3])
      worker.start()
      worker.join()

      worker.results # This will be inferred as Unknown by your LSP/Linter
      ```
      ```py
      from thread import ParallelProcessing

      def my_target(x: int) -> int:
        return x + 1

      worker = ParallelProcessing(function = my_target, dataset = [1, 2, 3])
      worker.start()
      worker.join()

      worker.results # This will be inferred as a list[int]
      ```
    </Callout>
  </ArgumentBody>
</ArgumentWrapper>

* dataset : Sequence[Data_In] = ()
  > This should be an interable sequence of arguments parsed to the `DataProcessor` function<br />
  > (e.g. tuple('foo', 'bar'))
  
* *overflow_args : Overflow_In
  > These are arguments parsed to [**thread.Thread**](./threading.md#parameters)

* **overflow_kwargs : Overflow_In
  > These are arguments parsed to [**thread.Thread**](./threading.md#parameters)<br />
  <Callout type="info">
    If `args` is present, then it will automatically be removed from kwargs and joined with `overflow_args`
  </Callout>
  

* **Raises** AssertionError: max_threads is invalid



### Attributes

These are attributes of [`ParallelProcessing`](#importing-the-class) class

* results : List[Data_Out]
  > The result value<br />
  > **Raises** [`ThreadNotInitializedError`](./exceptions.md#threadNotInitializedError)<br />
  > **Raises** [`ThreadNotRunningError`](./exceptions.md#threadnotrunningerror)<br />
  > **Raises** [`ThreadStillRunningError`](./exceptions.md#threadStillRunningError)



### Methods

These are methods of [`ParallelProcessing`](#importing-the-class) class

* start : () -> None
  > Initializes the threads and starts it<br />
  > **Raises** [`ThreadStillRunningError`](./exceptions.md#threadStillRunningError)

* is_alive : () -> bool
  > Indicates whether the thread is still alive<br />
  > **Raises** [`ThreadNotInitializedError`](./exceptions.md#threadNotInitializedError)

* get_return_values : () -> Data_Out
  > Halts the current thread execution until the thread completes

* join : () -> JoinTerminatedStatus
  > Halts the current thread execution until a thread completes or exceeds the timeout<br />
  > **Raises** [`ThreadNotInitializedError`](./exceptions.md#threadNotInitializedError)<br />
  > **Raises** [`ThreadNotRunningError`](./exceptions.md#threadnotrunningerror)

* kill : (yielding: bool = False, timeout: float = 5) -> bool
  > Schedules the thread to be killed<br />
  > If yielding is True, it halts the current thread execution until the thread is killed or the timeout is exceeded<br />
  > **Raises** [`ThreadNotInitializedError`](./exceptions.md#threadnotinitializederror)<br />
  > **Raises** [`ThreadNotRunningError`](./exceptions.md#threadnotrunningerror)<br />
  <Callout type="info">
    This only schedules the thread to be killed, and does not immediately kill the thread
  </Callout>

Now you know how to use the [`ParallelProcessing`](#importing-the-class) class!

[See here](./parallel-processing.md) for how to using the `thread.ParallelProcessing` class!